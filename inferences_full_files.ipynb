{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alberto/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "import librosa\n",
    "import lib.util as ut\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model we want to make inferences with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='my_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To divide audio files. When making inferences over whole audio files, we pass interval_step=sample_rate/2 to produce 50% overlapping chunks of 3 second audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_audio_file(path, intervals_seconds, interval_step, sample_rate=8000):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    # loads file and converts to the specified sample rate    \n",
    "    audio, fs = librosa.load(path, sample_rate)\n",
    "    \n",
    "    audio_array = []\n",
    "    for i in range(0, audio.shape[0], interval_step):   \n",
    "        interval = audio[i:i+sample_rate*intervals_seconds]\n",
    "#         print(\"interval from {} to {}\".format(i, i+sample_rate*intervals_seconds))\n",
    "        \n",
    "        # if the last interval is shorter han the interval in seconds we define we are going to ignore it\n",
    "        if interval.shape[0] < sample_rate*intervals_seconds:\n",
    "            break\n",
    "        else:\n",
    "            if (not ut.is_silence(interval,thresold_samples=0.70)):\n",
    "                audio_array.append(interval)\n",
    "            else:\n",
    "                print(\"Omitting chunk with silences in file {}\".format(path))\n",
    "\n",
    "    return np.array(audio_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Like the original create_tf_records but creating numpy array's instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks_from_raw(audio_path, file_names_df, num_samples):\n",
    "    \n",
    "    x_data = []\n",
    "    labels = []\n",
    "    tf_record_files = 1  \n",
    "    for file in os.listdir(audio_path):\n",
    "\n",
    "        file_path = audio_path + \"/\" + file\n",
    "        short_name = file.split(\".\")[0]\n",
    "\n",
    "        # if the file is in the dataframe with the file names(train or test) we divide it, if not we ignore\n",
    "        if short_name in file_names_df[\"0\"].values:\n",
    "            print(\"reading file {}\".format(file))\n",
    "\n",
    "            divided_file =  divide_audio_file(file_path, intervals_seconds, sample_rate)\n",
    "\n",
    "            file_label = file_names_df[file_names_df[\"0\"] == short_name][\"class\"].values[0]\n",
    "            labels_array = np.ones(divided_file.shape[0]) * file_label\n",
    "            \n",
    "            x_data.extend(divided_file)\n",
    "            labels.extend(labels_array)            \n",
    "            \n",
    "            if len(x_data) > num_samples:\n",
    "                tf_record_files += 1\n",
    "                break;\n",
    "                        \n",
    "        else:\n",
    "            print(\"file {} not in the dataframe\".format(file))\n",
    "       \n",
    "                 \n",
    "    return (x_data,labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## makes inference of a whole audio by dividing it into overlapping (50%) chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_audio(file_name,label):\n",
    "    file_path = audio_path + \"/\" + file_name\n",
    "    audio_chunks=divide_audio_file(file_path, intervals_seconds, int(sample_rate*1.5))\n",
    "    audio_chunks = audio_chunks.reshape([audio_chunks.shape[0],intervals_seconds * sample_rate,1])\n",
    "    labels_array = np.ones(audio_chunks.shape[0]) * label\n",
    "    predictions = model.predict(audio_chunks)\n",
    "#     print(labels_array.shape)\n",
    "#     print(audio_chunks.shape)\n",
    "#     vc = pd.DataFrame(predictions)[0].apply(lambda x: 0 if x < 0.5 else 1).value_counts()\n",
    "#     if (vc[0]<vc[1]):\n",
    "#         res = 1\n",
    "#     else:\n",
    "#         res = 0\n",
    "        \n",
    "    return (predictions)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get string labels from numeric ones to build a confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabels(x):\n",
    "    if (x>=0.5):\n",
    "        label = \"CY\"\n",
    "    else:\n",
    "        label = \"CN\"\n",
    "    return(label)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin of the execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alberto/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/alberto/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alberto/anaconda3/lib/python3.6/site-packages/keras/legacy/layers.py:74: UserWarning: The `MaxoutDense` layer is deprecated and will be removed after 06/2017.\n",
      "  warnings.warn('The `MaxoutDense` layer is deprecated '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alberto/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/alberto/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 24000, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 24000, 64)         8320      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 3000, 64)          0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 3000, 64, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3000, 64, 96)      374880    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 375, 64, 96)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 375, 64, 128)      430208    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 93, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 93, 64, 160)       348320    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 64, 160)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 1, 64, 160)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10240)             0         \n",
      "_________________________________________________________________\n",
      "maxout_dense_3 (MaxoutDense) (None, 128)               5243392   \n",
      "_________________________________________________________________\n",
      "maxout_dense_4 (MaxoutDense) (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 6,438,209\n",
      "Trainable params: 6,438,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(model_path)\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"./data/audiodata\"\n",
    "labels_file = \"./data/conflictlevel.csv\"\n",
    "\n",
    "intervals_seconds = 3\n",
    "sample_rate = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(labels_file, header=None)\n",
    "labels_df[\"class\"] = labels_df[1].apply(lambda x: 0 if x < 0 else 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(\"./data/train_files.csv\")\n",
    "test_df = pd.read_csv(\"./data/test_files.csv\")\n",
    "# validation_df = pd.read_csv(\"./data/validation_files.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08-01-23_780_810</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06-09-06_1470_1500</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08-01-09_1650_1680</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07-01-31_2040_2070</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-01-23_990_1020</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0    1  class\n",
       "0    08-01-23_780_810 -5.3      0\n",
       "1  06-09-06_1470_1500  4.6      1\n",
       "2  08-01-09_1650_1680 -0.2      0\n",
       "3  07-01-31_2040_2070  3.5      1\n",
       "4   08-01-23_990_1020 -2.5      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting for file 08-01-23_780_810.wav\n",
      "predicting for file 06-09-06_1470_1500.wav\n",
      "predicting for file 08-01-09_1650_1680.wav\n",
      "predicting for file 07-01-31_2040_2070.wav\n",
      "predicting for file 08-01-23_990_1020.wav\n"
     ]
    }
   ],
   "source": [
    "predictions_list = []\n",
    "\n",
    "for file, cl in test_df[[\"0\", \"class\"]].values[:5]:\n",
    "    pred = predict_one_audio(file + \".wav\",cl)\n",
    "    \n",
    "    print(\"predicting for file {}\".format(file + \".wav\"))\n",
    "    predictions_list.append([i for sublist in pred for i in sublist])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({\"prediction\": predictions_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = test_df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = test_df.join(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"avg\"] = final_df[\"prediction\"].apply(lambda x: np.mean(x))\n",
    "final_df[\"stdv\"] = final_df[\"prediction\"].apply(lambda x: np.std(x))\n",
    "final_df[\"positive\"] = final_df[\"prediction\"].apply(lambda x: sum(i >= 0.5 for i in x))\n",
    "final_df[\"negative\"] = final_df[\"prediction\"].apply(lambda x: sum(i < 0.5 for i in x))\n",
    "final_df[\"majority\"] = final_df.apply(lambda row: 1 if row[\"positive\"] >= row[\"negative\"] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>class</th>\n",
       "      <th>prediction</th>\n",
       "      <th>avg</th>\n",
       "      <th>stdv</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>majority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08-01-23_780_810</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>06-09-06_1470_1500</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08-01-09_1650_1680</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07-01-31_2040_2070</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-01-23_990_1020</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0    1  class  \\\n",
       "0    08-01-23_780_810 -5.3      0   \n",
       "1  06-09-06_1470_1500  4.6      1   \n",
       "2  08-01-09_1650_1680 -0.2      0   \n",
       "3  07-01-31_2040_2070  3.5      1   \n",
       "4   08-01-23_990_1020 -2.5      0   \n",
       "\n",
       "                                          prediction  avg  stdv  positive  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  0.0   0.0         0   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  0.0   0.0         0   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  0.0   0.0         0   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  0.0   0.0         0   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  0.0   0.0         0   \n",
       "\n",
       "   negative  majority  \n",
       "0        19         0  \n",
       "1        19         0  \n",
       "2        19         0  \n",
       "3        19         0  \n",
       "4        19         0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"./data/train_files.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelTr = np.vectorize(getLabels)\n",
    "pre_labels = labelTr(res)\n",
    "tru_labels = labelTr(y_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         CN       0.60      1.00      0.75         3\n",
      "         CY       0.00      0.00      0.00         2\n",
      "\n",
      "avg / total       0.36      0.60      0.45         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alberto/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "metrics = classification_report(tru_labels,pre_labels)\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
