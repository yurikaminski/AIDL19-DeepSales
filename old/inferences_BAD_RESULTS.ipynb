{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from keras.backend import manual_variable_initialization\n",
    "manual_variable_initialization(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(proto):\n",
    "\n",
    "    keys_to_features = {'sound': tf.FixedLenFeature([], tf.string),\n",
    "                        \"label\": tf.FixedLenFeature([], tf.float32)}\n",
    "    \n",
    "    # Load one example\n",
    "    parsed_features = tf.parse_single_example(proto, keys_to_features)\n",
    "    \n",
    "    # Turn the sound string back into an array\n",
    "    parsed_features['sound'] = tf.decode_raw(parsed_features['sound'], tf.float32)\n",
    "    \n",
    "    \n",
    "    return parsed_features['sound'], parsed_features[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(filepath, classification=True):\n",
    "    \n",
    "    files = [filepath + \"/\" + file for file in os.listdir(filepath)]\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "    \n",
    "    # Maps the parser on every filepath in the array. You can set the number of parallel loaders here\n",
    "    dataset = dataset.map(_parse_function, num_parallel_calls=4)\n",
    "    \n",
    "    # This dataset will go on forever\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    # Set the number of datapoints you want to load and shuffle \n",
    "    #dataset = dataset.shuffle(512)\n",
    "    \n",
    "    # Set the batchsize\n",
    "    dataset = dataset.batch(batchsize)\n",
    "    \n",
    "    # Create an iterator\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    # Create your tf representation of the iterator\n",
    "    sound, label = iterator.get_next()\n",
    "\n",
    "    # reshape\n",
    "    sound = tf.reshape(sound, [-1, 24000, 1])\n",
    "    label = tf.reshape(label, [-1, 1])\n",
    "    \n",
    "#     Create a one hot array for your labels\n",
    "#     label = tf.one_hot(label, NUM_CLASSES)\n",
    "\n",
    "    \n",
    "    return sound, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabels(x):\n",
    "    if (x>=0.5):\n",
    "        label = \"CY\"\n",
    "    else:\n",
    "        label = \"CN\"\n",
    "    return(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test samples= 8008\n",
      "validation samples = 5990\n",
      "train samples = 26007\n"
     ]
    }
   ],
   "source": [
    "test_filepath = \"./data/tf_data/test\"\n",
    "validation_filepath = \"./data/tf_data/validation\"\n",
    "train_filepath = \"./data/tf_data/train\"\n",
    "\n",
    "\n",
    "\n",
    "test_samples = sum([int(file.split(\"_\")[0]) for file in os.listdir(test_filepath)])\n",
    "validation_samples = sum([int(file.split(\"_\")[0]) for file in os.listdir(validation_filepath)])\n",
    "train_samples = sum([int(file.split(\"_\")[0]) for file in os.listdir(train_filepath)])\n",
    "\n",
    "\n",
    "batchsize = train_samples\n",
    "print(\"test samples=\",test_samples)\n",
    "print(\"validation samples =\",validation_samples)\n",
    "print(\"train samples =\",train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(24000), Dimension(1)])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchsize = 55\n",
    "sound_test, label_test = create_dataset(test_filepath)\n",
    "sound_validation, label_validation = create_dataset(validation_filepath)\n",
    "sound_train, label_train = create_dataset(train_filepath)\n",
    "\n",
    "\n",
    "sound_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "#model = load_model('./trained_models/model_paper/model.h5')\n",
    "# inputs = layers.Input(shape=(data.shape[1],1))\n",
    "inputs = layers.Input(tensor=sound_train)\n",
    "\n",
    "conv1 = layers.Conv1D(filters=64, kernel_size=129, padding=\"same\")(inputs)\n",
    "pool1 = layers.MaxPool1D(8)(conv1)\n",
    "\n",
    "reshape = layers.Reshape((3000,64,1))(pool1)\n",
    "\n",
    "conv2 = layers.Conv2D(filters=96, kernel_size=(61,1), padding=\"same\", activation='relu')(reshape)\n",
    "#conv2 = layers.Conv2D(filters=10, kernel_size=(61,64), padding=\"same\", activation='relu')(reshape)\n",
    "\n",
    "pool2 = layers.MaxPool2D((8,1))(conv2)\n",
    "conv3 = layers.Conv2D(filters=128, kernel_size=(35,1), padding=\"same\", activation='relu')(pool2)\n",
    "pool3 = layers.MaxPool2D((4,1))(conv3)\n",
    "conv4 = layers.Conv2D(filters=160, kernel_size=(17,1), padding=\"same\", activation='relu')(pool3)\n",
    "pool4 = layers.MaxPool2D((12,1))(conv4)\n",
    "avgpool = layers.AveragePooling2D((5,1))(pool4)\n",
    "\n",
    "flatten = layers.Flatten()(avgpool)\n",
    "\n",
    "dense1 = layers.MaxoutDense(output_dim=128,nb_feature=4)(flatten)\n",
    "dropout1 = layers.Dropout(0.5)(dense1)\n",
    "dense2 = layers.MaxoutDense(output_dim=64, nb_feature=4)(dropout1)\n",
    "dropout2 = layers.Dropout(0.5)(dense2)\n",
    "\n",
    "# max_out = maximum([Dense(neurons, **dense_args)(input_layer) for _ in range(n_pieces)])\n",
    "\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(dropout2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./trained_models/model_paper/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 24000, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 24000, 64)         8320      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 3000, 64)          0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 3000, 64, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3000, 64, 96)      5952      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 375, 64, 96)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 375, 64, 128)      430208    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 93, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 93, 64, 160)       348320    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 64, 160)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 1, 64, 160)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10240)             0         \n",
      "_________________________________________________________________\n",
      "maxout_dense_3 (MaxoutDense) (None, 128)               5243392   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "maxout_dense_4 (MaxoutDense) (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 6,069,281\n",
      "Trainable params: 6,069,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model = Model(inputs=inputs, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 24000, 1)\n"
     ]
    }
   ],
   "source": [
    "#prediction = model.predict(sound_test,steps=test_samples/batchsize,batch_size=batchsize)\n",
    "with tf.Session() as s:\n",
    "    x = np.reshape(s.run(sound_train[0:1000]),[1000,24000,1])\n",
    "    y = np.reshape(s.run(label_train[0:1000]),[1000,1])\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-39efe4893fa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtotal_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msound_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         res=model.evaluate(st,lt,\n\u001b[1;32m     11\u001b[0m                     steps=1,batch_size=None)\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m       raise TypeError(\n\u001b[0;32m--> 442\u001b[0;31m           \u001b[0;34m\"Tensor objects are only iterable when eager execution is \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m           \"enabled. To iterate over this tensor use tf.map_fn.\")\n\u001b[1;32m    444\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Tensor objects are only iterable when eager execution is enabled. To iterate over this tensor use tf.map_fn."
     ]
    }
   ],
   "source": [
    "#res=model.predict(x)\n",
    "#res=model.evaluate(tf.reshape(sound_test,[8008,1,24000,1]),tf.reshape(label_test,[8008,1,1,1]),\n",
    "#    steps=8008)\n",
    "sound_test = tf.reshape(sound_test,[8008,1,24000,1])\n",
    "label_test = tf.reshape(label_test,[8008,1,1])\n",
    "\n",
    "total_res = []\n",
    "with tf.Session() as s:\n",
    "    for st,lt in zip (sound_test, label_test):\n",
    "        res=model.evaluate(st,lt,\n",
    "                    steps=1,batch_size=None)\n",
    "        total_res.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(8008), Dimension(1), Dimension(24000), Dimension(1)])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sound_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.318207491248846, 0.48]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['CN'],\n",
       "       ['CY'],\n",
       "       ['CN'],\n",
       "       ['CN']], dtype='<U2')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelTr = np.vectorize(getLabels)\n",
    "pre_labels = labelTr(res)\n",
    "tru_labels = labelTr(y)\n",
    "tru_labels[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CN       0.56      0.58      0.57      4451\n",
      "          CY       0.45      0.43      0.44      3557\n",
      "\n",
      "    accuracy                           0.51      8008\n",
      "   macro avg       0.50      0.50      0.50      8008\n",
      "weighted avg       0.51      0.51      0.51      8008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "metrics = classification_report(tru_labels,pre_labels)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5990, 24000, 1)\n"
     ]
    }
   ],
   "source": [
    "#prediction = model.predict(sound_test,steps=test_samples/batchsize,batch_size=batchsize)\n",
    "x = np.reshape(tf.Session().run(sound_validation[0:validation_samples]),[validation_samples,24000,1])\n",
    "y = np.reshape(tf.Session().run(label_validation[0:validation_samples]),[validation_samples,1])\n",
    "print(x.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelTr = np.vectorize(getLabels)\n",
    "pre_labels = labelTr(res)\n",
    "tru_labels = labelTr(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CN       0.64      0.59      0.61      3802\n",
      "          CY       0.37      0.42      0.39      2188\n",
      "\n",
      "    accuracy                           0.53      5990\n",
      "   macro avg       0.51      0.51      0.50      5990\n",
      "weighted avg       0.54      0.53      0.53      5990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "metrics = classification_report(tru_labels,pre_labels)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(tru_labels,pre_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2249, 1553],\n",
       "       [1270,  918]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
