{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "Collecting decorator>=3.0.0 (from librosa)\n",
      "  Using cached https://files.pythonhosted.org/packages/5f/88/0075e461560a1e750a0dcbf77f1d9de775028c37a19a346a6c565a257399/decorator-4.4.0-py2.py3-none-any.whl\n",
      "Collecting audioread>=2.0.0 (from librosa)\n",
      "Collecting resampy>=0.2.0 (from librosa)\n",
      "Collecting six>=1.3 (from librosa)\n",
      "  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Collecting joblib>=0.12 (from librosa)\n",
      "  Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl\n",
      "Collecting numba>=0.38.0 (from librosa)\n",
      "  Using cached https://files.pythonhosted.org/packages/84/8e/18e74153e6bddda68a6ff9382b9d347d5da8599ea2326b34ded099df5216/numba-0.44.1-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting numpy>=1.8.0 (from librosa)\n",
      "  Using cached https://files.pythonhosted.org/packages/bb/ef/d5a21cbc094d3f4d5b5336494dbcc9550b70c766a8345513c7c24ed18418/numpy-1.16.4-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting scipy>=1.0.0 (from librosa)\n",
      "  Using cached https://files.pythonhosted.org/packages/14/49/8f13fa215e10a7ab0731cc95b0e9bb66cf83c6a98260b154cfbd0b55fb19/scipy-1.3.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting scikit-learn!=0.19.0,>=0.14.0 (from librosa)\n",
      "  Using cached https://files.pythonhosted.org/packages/99/6c/bbbf3452cd5c8ed8e6cb51d37e06ebea3113d347085a59a21f19ee76c8eb/scikit_learn-0.21.2-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting llvmlite>=0.29.0 (from numba>=0.38.0->librosa)\n",
      "  Using cached https://files.pythonhosted.org/packages/fc/8c/6412b14976f90d703279b5cd53c6f036e4e1fda434007f305e8a1e103d06/llvmlite-0.29.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Installing collected packages: decorator, audioread, numpy, scipy, six, llvmlite, numba, resampy, joblib, scikit-learn, librosa\n",
      "Successfully installed audioread-2.1.8 decorator-4.4.0 joblib-0.13.2 librosa-0.6.3 llvmlite-0.29.0 numba-0.44.1 numpy-1.16.4 resampy-0.2.1 scikit-learn-0.21.2 scipy-1.3.0 six-1.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "import librosa\n",
    "\n",
    "import tensorflow as tf\n",
    "import lib.util as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"./data/audiodata\"\n",
    "labels_file = \"./data/conflictlevel.csv\"\n",
    "\n",
    "intervals_seconds = 3\n",
    "sample_rate = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(labels_file, header=None)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels_df[1].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly separate files in Train, Test data validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_val_split(df, test_percentage, validation_percentage):\n",
    "    \"\"\"\n",
    "    shuffles the data and divide the dataframe in train, test and validation dataframes\n",
    "    according to the percentages given\n",
    "    returns the 3 dataframes\n",
    "    \"\"\"\n",
    "    \n",
    "    indices = np.random.permutation(df.index)\n",
    "    test_size = int(df.shape[0]*test_percentage)\n",
    "    val_size = int(df.shape[0]*validation_percentage)\n",
    "    \n",
    "    test = df.iloc[indices[:test_size]]\n",
    "    validation = df.iloc[indices[test_size:test_size+val_size]]\n",
    "    train = df.iloc[indices[test_size+val_size:]]\n",
    "    \n",
    "    assert (test.shape[0]+validation.shape[0]+train.shape[0]) == df.shape[0]\n",
    "    \n",
    "    return train, test, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, validation_df = train_test_val_split(labels_df, 0.2, 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"./data/train_files.csv\", index=False)\n",
    "test_df.to_csv(\"./data/test_files.csv\", index=False)\n",
    "validation_df.to_csv(\"./data/validation_files.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"0\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/train_files.csv\", header=None, names=[0,1, \"class\"], skiprows=1)\n",
    "#test_df = pd.read_csv(\"./data/test_files.csv\")\n",
    "#validation_df = pd.read_csv(\"./data/validation_files.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for training (convert sample rate, divide files in N seconds intervals, create dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_audio_file(path, intervals_seconds, interval_step, sample_rate=8000):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # loads file and converts to the specified sample rate    \n",
    "    audio, fs = librosa.load(path, sample_rate)\n",
    "    \n",
    "    audio_array = []\n",
    "    for i in range(0, audio.shape[0], interval_step):   \n",
    "        interval = audio[i:i+sample_rate*intervals_seconds]\n",
    "#         print(\"interval from {} to {}\".format(i, i+sample_rate*intervals_seconds))\n",
    "        \n",
    "        # if the last interval is shorter han the interval in seconds we define we are going to ignore it\n",
    "        if interval.shape[0] < sample_rate*intervals_seconds:\n",
    "            break\n",
    "        else:\n",
    "            if (not ut.is_silence(interval,thresold_samples=0.70)):\n",
    "                audio_array.append(interval)\n",
    "            else:\n",
    "                print(\"Omitting chunk with silences in file {}\".format(path))\n",
    "\n",
    "    return np.array(audio_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(audio_path, file_names_df):\n",
    "    \n",
    "    x_data = []\n",
    "    labels = []\n",
    "    \n",
    "    for file in os.listdir(audio_path):\n",
    "\n",
    "        file_path = audio_path + \"/\" + file\n",
    "\n",
    "        short_name = file.split(\".\")[0]\n",
    "\n",
    "        # if the file is in the dataframe with the file names(train or test) we divide it, if not we ignore\n",
    "        if short_name in file_names_df[0].values:\n",
    "            print(\"reading file {}\".format(file))\n",
    "\n",
    "            divided_file =  divide_audio_file(file_path, intervals_seconds, sample_rate)\n",
    "\n",
    "            file_label = file_names_df[file_names_df[0] == short_name][\"class\"].values[0]\n",
    "            labels_array = np.ones(divided_file.shape[0]) * file_label\n",
    "            print(labels_array)\n",
    "            \n",
    "            x_data.extend(divided_file)\n",
    "            labels.extend(labels_array)\n",
    "            \n",
    "        else:\n",
    "            print(\"file {} not in the dataframe\".format(file))\n",
    "\n",
    "    return np.array(x_data), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work with tf records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_save_records(x_data, labels, save_path, tf_record_files):\n",
    "    \n",
    "    filename = '{}/{}_{}.tfrecords'.format(save_path, len(x_data), tf_record_files)\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "\n",
    "    for i, interval in enumerate(x_data):\n",
    "        feature = {'sound':  _bytes_feature(tf.compat.as_bytes(interval.tostring())),\n",
    "                   'label':  _float_feature(labels[i])}\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        writer.write(example.SerializeToString())\n",
    "\n",
    "    writer.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_records(audio_path, file_names_df, save_path):\n",
    "    \n",
    "    x_data = []\n",
    "    labels = []\n",
    "    tf_record_files = 1  \n",
    "    for file in os.listdir(audio_path):\n",
    "\n",
    "        file_path = audio_path + \"/\" + file\n",
    "        short_name = file.split(\".\")[0]\n",
    "\n",
    "        # if the file is in the dataframe with the file names(train or test) we divide it, if not we ignore\n",
    "        if short_name in file_names_df[0].values:\n",
    "            print(\"reading file {}\".format(file))\n",
    "\n",
    "            divided_file =  divide_audio_file(file_path, intervals_seconds, sample_rate)\n",
    "\n",
    "            file_label = file_names_df[file_names_df[0] == short_name][\"class\"].values[0]\n",
    "            labels_array = np.ones(divided_file.shape[0]) * file_label\n",
    "#             print(labels_array)\n",
    "            \n",
    "            x_data.extend(divided_file)\n",
    "            labels.extend(labels_array)            \n",
    "            \n",
    "            # if we already have more than 2500 files dump them in a tf records file\n",
    "            if len(x_data) > 2500:\n",
    "                convert_and_save_records(x_data, labels, save_path, tf_record_files)\n",
    "            \n",
    "                x_data = []\n",
    "                labels = []\n",
    "                tf_record_files += 1\n",
    "                        \n",
    "        else:\n",
    "            print(\"file {} not in the dataframe\".format(file))\n",
    "       \n",
    "    #  for the final data\n",
    "    if len(x_data) > 0:\n",
    "        convert_and_save_records(x_data, labels, save_path, tf_record_files)\n",
    "                \n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tf_records(audio_path, train_df,\"./data/tf_data/train_regression\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tf_records(audio_path, validation_df,\"./data/tf_data/validation_regression\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = create_dataset(audio_path, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dataset(x, y, \"./data/train_dataset.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
